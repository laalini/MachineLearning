{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling as pdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C:/Users/Dell/Downloads/Compressed/Hacakthon/Hacakthon/train.csv\")\n",
    "test_data = pd.read_csv(\"C:/Users/Dell/Downloads/Compressed/Hacakthon/Hacakthon/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loan_id', 'source', 'financial_institution', 'interest_rate',\n",
       "       'unpaid_principal_bal', 'loan_term', 'origination_date',\n",
       "       'first_payment_date', 'loan_to_value', 'number_of_borrowers',\n",
       "       'debt_to_income_ratio', 'borrower_credit_score', 'loan_purpose',\n",
       "       'insurance_percent', 'co-borrower_credit_score', 'insurance_type', 'm1',\n",
       "       'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9', 'm10', 'm11', 'm12',\n",
       "       'm13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " train_data.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['origination_date']=pd.to_datetime(train_data['origination_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         1\n",
      "1         1\n",
      "2         1\n",
      "3         1\n",
      "4         1\n",
      "5         1\n",
      "6         1\n",
      "7         1\n",
      "8         1\n",
      "9         1\n",
      "10        1\n",
      "11        1\n",
      "12        1\n",
      "13        1\n",
      "14        1\n",
      "15        1\n",
      "16        1\n",
      "17        1\n",
      "18        1\n",
      "19        1\n",
      "20        1\n",
      "21        1\n",
      "22        1\n",
      "23        1\n",
      "24        1\n",
      "25        1\n",
      "26        1\n",
      "27        1\n",
      "28        1\n",
      "29        1\n",
      "         ..\n",
      "116028    0\n",
      "116029    0\n",
      "116030    0\n",
      "116031    0\n",
      "116032    0\n",
      "116033    0\n",
      "116034    0\n",
      "116035    0\n",
      "116036    0\n",
      "116037    0\n",
      "116038    0\n",
      "116039    0\n",
      "116040    0\n",
      "116041    0\n",
      "116042    0\n",
      "116043    0\n",
      "116044    0\n",
      "116045    0\n",
      "116046    0\n",
      "116047    0\n",
      "116048    0\n",
      "116049    0\n",
      "116050    0\n",
      "116051    0\n",
      "116052    0\n",
      "116053    0\n",
      "116054    0\n",
      "116055    0\n",
      "116056    0\n",
      "116057    0\n",
      "Name: m13, Length: 116058, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Labels = train_data['m13']\n",
    "print(Labels)\n",
    "drop_cols=['m13','loan_id','number_of_borrowers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([115422,    636], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels1 = list(Labels)\n",
    "np.bincount(Labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['first_payment_date']=pd.to_datetime(train_data['first_payment_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         2\n",
      "1         1\n",
      "2         2\n",
      "3         0\n",
      "4         0\n",
      "5         1\n",
      "6         0\n",
      "7         1\n",
      "8         0\n",
      "9         0\n",
      "10        0\n",
      "11        0\n",
      "12        0\n",
      "13        0\n",
      "14        1\n",
      "15        0\n",
      "16        1\n",
      "17        1\n",
      "18        1\n",
      "19        1\n",
      "20        0\n",
      "21        1\n",
      "22        0\n",
      "23        0\n",
      "24        0\n",
      "25        0\n",
      "26        1\n",
      "27        0\n",
      "28        0\n",
      "29        1\n",
      "         ..\n",
      "116028    1\n",
      "116029    0\n",
      "116030    2\n",
      "116031    1\n",
      "116032    1\n",
      "116033    0\n",
      "116034    0\n",
      "116035    1\n",
      "116036    1\n",
      "116037    0\n",
      "116038    0\n",
      "116039    0\n",
      "116040    2\n",
      "116041    1\n",
      "116042    0\n",
      "116043    0\n",
      "116044    0\n",
      "116045    0\n",
      "116046    0\n",
      "116047    0\n",
      "116048    0\n",
      "116049    1\n",
      "116050    0\n",
      "116051    0\n",
      "116052    0\n",
      "116053    1\n",
      "116054    2\n",
      "116055    0\n",
      "116056    0\n",
      "116057    2\n",
      "Name: source, Length: 116058, dtype: int64\n",
      "Shape of matrix after one hot encodig  (116058, 43)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "fi_tfidf = vectorizer.fit_transform(train_data['financial_institution'])\n",
    "train_data['source'] = train_data['source'].replace(to_replace=['X','Y','Z'],value=[0,1,2])\n",
    "print(train_data['source'])\n",
    "#source=  vectorizer.fit_transform(train_data['source'])\n",
    "#oan_purposse= vectorizer.fit_transform(train_data['loan_purpose'])\n",
    "\n",
    "print(\"Shape of matrix after one hot encodig \",fi_tfidf.shape)\n",
    "#rint(\"Shape of matrix after one hot encodig \",loan_purposse)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# price_standardized = standardScalar.fit(project_data['price'].values)\n",
    "# this will rise the error\n",
    "# ValueError: Expected 2D array, got 1D array instead: array=[725.05 213.03 329.   ... 399.   287.73   5.5 ].\n",
    "# Reshape your data either using array.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "dropcolus=['loan_purpose','financial_institution','origination_date','first_payment_date','loan_id','m13']\n",
    "x= train_data.drop(dropcolus,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : 9124.134644762702, Standard deviation : 48721.490487718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# price_standardized = standardScalar.fit(project_data['price'].values)\n",
    "# this will rise the error\n",
    "# ValueError: Expected 2D array, got 1D array instead: array=[725.05 213.03 329.   ... 399.   287.73   5.5 ].\n",
    "# Reshape your data either using array.reshape(-1, 1)\n",
    "\n",
    "price_scalar = StandardScaler()\n",
    "price_scalar.fit(x.values.reshape(-1,1)) # finding the mean and standard deviation of this data\n",
    "print(f\"Mean : {price_scalar.mean_[0]}, Standard deviation : {np.sqrt(price_scalar.var_[0])}\")\n",
    "\n",
    "# Now standardize the data with above maen and variance\n",
    "price_standardized = price_scalar.transform(x.values.reshape(116058,23 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116058, 66)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "# with the same hstack function we are concatinating a sparse matrix and a dense matirx :)\n",
    "X = hstack((fi_tfidf,price_standardized))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# clf = svm.SVC(kernel='linear')\n",
    "# clf.fit(X,Labels)\n",
    "# print(clf.predict(X))\n",
    "# y_pred=clf.predict(X)\n",
    "# for i in y_pred:\n",
    "#     if (i==1):\n",
    "#         print(\"hurray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(ratio='auto')\n",
    "X,Labels = smt.fit_sample(X,Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf =RandomForestClassifier()\n",
    "params = {'class_weight':[{0:neg_weight, 1:1} for neg_weight in np.arange(1.0, 5.0, 0.5)]} \n",
    "gs = GridSearchCV(estimator=clf, param_grid=params, cv=5)\n",
    "gs.fit(X, Labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(learning_rate = 0.055,max_depth = 4)\n",
    "#train_x, test_x, train_Y, test_y = train_test_split(X_train,Labels,train_size=0.8)\n",
    "# rfe = RFE(model, 20)\n",
    "# rfe = rfe.fit(train_x,Labels)\n",
    "model.fit(X,Labels)\n",
    "# print(rfe.support_)\n",
    "# print(rfe.ranking_)\n",
    "# xgb_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =gs.predict(X)\n",
    "sklearn.metrics.f1_score(Labels, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "fi_tfidf = vectorizer.fit_transform(test_data['financial_institution'])\n",
    "test_data['source'] = test_data['source'].replace(to_replace=['X','Y','Z'],value=[0,1,2])\n",
    "print(test_data['source'])\n",
    "#source=  vectorizer.fit_transform(train_data['source'])\n",
    "#oan_purposse= vectorizer.fit_transform(train_data['loan_purpose'])\n",
    "\n",
    "print(\"Shape of matrix after one hot encodig \",fi_tfidf.shape)\n",
    "#rint(\"Shape of matrix after one hot encodig \",loan_purposse)\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "dropcolus=['loan_purpose','financial_institution','origination_date','first_payment_date','loan_id']\n",
    "z= test_data.drop(dropcolus,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# price_standardized = standardScalar.fit(project_data['price'].values)\n",
    "# this will rise the error\n",
    "# ValueError: Expected 2D array, got 1D array instead: array=[725.05 213.03 329.   ... 399.   287.73   5.5 ].\n",
    "# Reshape your data either using array.reshape(-1, 1)\n",
    "\n",
    "price_scalar = StandardScaler()\n",
    "price_scalar.fit(x.values.reshape(-1,1)) # finding the mean and standard deviation of this data\n",
    "print(f\"Mean : {price_scalar.mean_[0]}, Standard deviation : {np.sqrt(price_scalar.var_[0])}\")\n",
    "\n",
    "# Now standardize the data with above maen and variance.\n",
    "\n",
    "price_standardize = price_scalar.transform(z.values.reshape(35866,23 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "# with the same hstack function we are concatinating a sparse matrix and a dense matirx :)\n",
    "Z = hstack((fi_tfidf,price_standardize))\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =gs.predict(Z)\n",
    "# for i in pred:\n",
    "#     if(i==1):\n",
    "#         print(\"Hurray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['loan_id','m13']\n",
    "output=pd.DataFrame(columns=cols)\n",
    "print(output.columns)\n",
    "output['loan_id']=test_data['loan_id']\n",
    "output['m13']=pred\n",
    "output.to_csv(\"pred1.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

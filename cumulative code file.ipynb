{"cells":[{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"colab_type":"code","id":"e_RdvH3KMWPv","outputId":"1fb1251a-e01d-492f-ccf9-10e4342ae8e1","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas_profiling as pdp\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.sparse import hstack\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.manifold import TSNE\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nfrom scipy.stats import pearsonr\nfrom sklearn.feature_selection import RFE\nimport lightgbm as lgb \nfrom xgboost import XGBClassifier\n","execution_count":536,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"X2uQTl2KMYFD","trusted":true},"cell_type":"code","source":"import pandas_profiling as pdp\n\n# from google.colab import drive\n# drive.mount('/content/drive')\n# %cd drive/My\\ Drive/Data","execution_count":537,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"ftIfVN8oMWP5","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/india-ml-hiring-av/train.csv\")\ntest_data = pd.read_csv(\"../input/india-ml-hiring-av/test.csv\")","execution_count":538,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns\ntrain_data.profile_report()","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"qbBBJYo1MWQB","trusted":true},"cell_type":"code","source":"Labels = train_data['m13']\n\n#print(Labels)\n#X=train_data['interest_rate','unpaid_principal_bal','loan_term','loan_to_value','number_of_borrowers','debt_to_income_ratio','borrower_credit_score','co-borrower_credit_score','m1','m2','m3','m4','m5','m6','m7','m8','m9','m10','m11','m12']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def firstpayment(train_data,k):\n    firstpayment = []\n    if(k==0):\n        for i in range(len(train_data['origination_date'])):\n            days = int(train_data['first_payment_date'][i].split('/')[0]) - int(train_data['origination_date'][i].split('-')[1])\n            firstpayment.append(days)\n    if(k==1):\n        months = {\"Feb\":2,\"Mar\":3,\"Apr\":4,\"May\":5}\n        for i in range(len(train_data['origination_date'])):\n            var = months[test_X['first_payment_date'][i].split('-')[0]] - int(test_X['origination_date'][i].split('/')[1])\n            firstpayment.append(var)\n    train_data['firstpayment']=firstpayment\n    train_data.drop(columns = ['origination_date','first_payment_date'],inplace = True)\n    return train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mdf(k):\n    train_data1 = pd.read_csv(\"../input/india-ml-hiring-av/train.csv\")\n    test_data1 = pd.read_csv(\"../input/india-ml-hiring-av/test.csv\")\n    cols=['var0','var1','var2','var3','var4','var5','var6','var7','var8','var9','var10']\n    mdf=pd.DataFrame(columns=cols)\n    mdf1=pd.DataFrame(columns=['val'])\n    if(k==0):\n        mdf1['val']=train_data1['m1']-train_data1['m12']\n        cols1=['m1','m2','m3','m4','m5','m6','m7','m8','m9','m10','m11','m12']\n        for i in range(0,11):\n            mdf[cols[i]]=train_data1[cols1[i+1]]-train_data1[cols1[i]]\n    #mdf.fillna(0)\n            dilmat=pd.concat([mdf1, mdf],axis=1)\n            dilmat.fillna(0)\n            dilmat.replace(' ',0)\n    if(k==1):\n        mdf1['val']=test_data1['m1']-test_data1['m12']\n        cols1=['m1','m2','m3','m4','m5','m6','m7','m8','m9','m10','m11','m12']\n        for i in range(0,11):\n            mdf[cols[i]]=test_data1[cols1[i+1]]-test_data1[cols1[i]]\n    #mdf.fillna(0)\n            dilmat=pd.concat([mdf1, mdf],axis=1)\n            dilmat.fillna(0)\n            dilmat.replace(' ',0)\n    return dilmat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode(df,columns,prefix):\n    columns = columns\n    df2 = pd.get_dummies(df,columns = columns, prefix = ['s','f','l'])\n    #df2.drop(['source','financial_institution','loan_purpose'],axis =1)\n    return df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_Select(X,Labels):\n    feature = []\n    from scipy.stats import pearsonr\n    for i in X.columns:\n        correlation, _ = pearsonr(X[i],Labels)\n        if abs(correlation)>0.01:\n            feature.append(i)\n            print(i+'\\t\\t\\t\\t '+str(correlation))\n    print(feature)\n   ","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"qnPwQwSuMWQI","trusted":true},"cell_type":"code","source":"def preprocess(train_data,k):\n    train_data['firstpayment'] = firstpayment(train_data,k)\n#     train_data.drop(columns = ['origination_date','first_payment_date'],axis =1,inplace = True)\n    train_data = encode(train_data,['source','financial_institution','loan_purpose'],['s','f','l'])\n    train_data.drop('loan_id',axis=1)\n    feature_Select(train_data,Labels)\n    df4= train_data[['interest_rate', 'unpaid_principal_bal', 'loan_term', 'loan_to_value','debt_to_income_ratio','borrower_credit_score', 'co-borrower_credit_score','source_X','source_Y','lp_A23','lp_B12','lp_C86']]\n    #mdf.drop('m13')\n    dilmat=mdf(k)\n    X =pd.concat([df4,dilmat], axis=1)\n    sm = SMOTE(random_state=2)\n    X_train,Labels = sm.fit_sample(X,Labels)\n      \n    return X_train\n# price_standardized = standardScalar.fit(project_data['price'].values)\n# this will rise the error\n# ValueError: Expected 2D array, got 1D array instead: array=[725.05 213.03 329.   ... 399.   287.73   5.5 ].\n# Reshape your data either using array.reshape(-1, 1)\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"6x2U0m8UMWQN","trusted":true},"cell_type":"code","source":"X_train = preprocess(train_data,0)\n#X_train.columns\nprint(X_train)\n\n#train_data.drop(['m13','loan_id','source','financial_institution','loan_purpose'],axis= 1,inplace= True)\n#features= feature_Select(X,Labels)\n#X_train= X[features]\n\nX_test= preprocess(test_data,1)\n#test_data.drop(['loan_id','source','financial_institution','loan_purpose'],axis= 1,inplace= True)\n\n#X_test= Y[features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Labels1 = list(Labels)\nnp.bincount(Labels1)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"Uy6M3t_QMWQc","trusted":true},"cell_type":"code","source":"\n# from sklearn import svm\n# wclf = svm.SVC(kernel='linear', class_weight={1:10})\n# wclf.fit(X, Labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def model_Selection():\n#     models = []\n#     models.append(('LR', LogisticRegression()))\n#     models.append(('LDA', LinearDiscriminantAnalysis()))\n#     models.append(('KNN', KNeighborsClassifier()))\n#     models.append(('CART', DecisionTreeClassifier()))\n#     models.append(('NB', GaussianNB()))\n#     models.append(('SVM', SVC()))\n# # evaluate each model in turn\n#     results = []\n#     names = []\n#     scoring = 'accuracy'\n#     for name, model in models:\n#         kfold = model_selection.KFold(n_splits=10, random_state=seed)\n#         cv_results = model_selection.cross_val_score(model, X_trian,Labels, cv=kfold, scoring=scoring)\n#         results.append(cv_results)\n#         names.append(name)\n#         msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n#         print(msg)\n# # boxplot algorithm comparison\n#     fig = plt.figure()\n#     fig.suptitle('Algorithm Comparison')\n#     ax = fig.add_subplot(111)\n#     plt.boxplot(results)\n#     ax.set_xticklabels(names)\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdata=lgb.Dataset(X_train,label=Labels)\nparam = {'num_leaves':150, 'objective':'binary','max_depth':7,'learning_rate':.05,'max_bin':200}\nparam['metric'] = ['auc', 'binary_logloss']\nnum_round=50\n# start=datetime.now()\nlgbm=lgb.train(param,tdata,num_round)\n#stop=datetime.now()\nlgb_predict=lgbm.predict(X_test)\n#df3.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBClassifier(learning_rate = 0.055,max_depth = 4)\n#train_x, test_x, train_Y, test_y = train_test_split(X_train,Labels,train_size=0.8)\n# rfe = RFE(model, 20)\n# rfe = rfe.fit(train_x,Labels)\nmodel.fit(X_train,Labels)\n# print(rfe.support_)\n# print(rfe.ranking_)\nxgb_predict = model.predict(X_test)\n    \nprint( \"Train Accuracy :: \", accuracy_score(train_Y, model.predict(train_x)))\nprint( \"Test Accuracy  :: \", accuracy_score(test_y, xgb_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_test6 = {\n 'reg_alpha':[0.005]\n}\nparams = {'class_weight':[{0:neg_weight, 1:1} for neg_weight in np.arange(1.0, 5.0, 0.5)]} \n# train_x, test_x, train_Y, test_y = train_test_split(X_train,Labels,train_size=0.8)\nfrom sklearn.model_selection import GridSearchCV\ngsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.055,max_depth=4) ,param_grid=param_test6,scoring='f1',n_jobs=4,iid=False, cv=5)\ngsearch6.fit(X_train,Labels)\ngsearch6.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"xQ600U7DMWQ0","trusted":true},"cell_type":"code","source":"\nclf =RandomForestClassifier()\nparams = {'class_weight':[{0:neg_weight, 1:1} for neg_weight in np.arange(1.0, 5.0, 0.5)]} \ngs = GridSearchCV(estimator=clf, param_grid=params, cv=5)\ngs.fit(X_train, Labels)\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"6NT5_VrkDtcI","trusted":true},"cell_type":"code","source":"gs.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"YCQjiarHMWRU","trusted":true},"cell_type":"code","source":"def adaboost(X_train, X_test,Labels):\n    model = AdaBoostClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train,Labels)\n    y_pred = model.predict(X_test) \n    return y_pred\n# AdaBoost\ny_baseline = adaboost(X_train, X_test, Labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RUS\nX_full = X_train.copy()\nX_full['m13'] = Labels[1]\nX_maj = X_full[X_full.target==0]\nX_min = X_full[X_full.target==1]\nX_maj_rus = resample(X_maj,replace=False,n_samples=len(X_min),random_state=44)\nX_rus = pd.concat([X_maj_rus, X_min])\nX_train_rus = X_rus.drop(['m13'], axis=1)\ny_train_rus = X_rus.target\ny_rus = adaboost(X_train_rus, X_test, y_train_rus)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"yMIJq_GSMWRb","trusted":true},"cell_type":"code","source":"#sklearn.metrics.f1_score(Labels, X_test)\ntest_data1 = pd.read_csv(\"../input/india-ml-hiring-av/test.csv\")\ncols=['loan_id','m13']\noutput=pd.DataFrame(columns=cols)\nprint(output.columns)\noutput['loan_id']=test_data1['loan_id']\noutput['m13']=lgb_predict\noutput.to_csv(\"pred1.csv\", index=False, header=True)","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DataML (4).ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}
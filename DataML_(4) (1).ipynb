{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "DataML (4).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_RdvH3KMWPv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1fb1251a-e01d-492f-ccf9-10e4342ae8e1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_profiling as pdp\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2uQTl2KMYFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas_profiling as pdp\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive/Data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftIfVN8oMWP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_data = pd.read_csv(\"train.csv\")\n",
        "test_data = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXYo9GLuMWP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbBBJYo1MWQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Labels = train_data['m13']\n",
        "train_data.drop('m13',axis= 1,inplace= True)\n",
        "#print(Labels)\n",
        "#X=train_data['interest_rate','unpaid_principal_bal','loan_term','loan_to_value','number_of_borrowers','debt_to_income_ratio','borrower_credit_score','co-borrower_credit_score','m1','m2','m3','m4','m5','m6','m7','m8','m9','m10','m11','m12']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksyaIDy4M7De",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def responseTime(train_data,k):\n",
        "  l=[]\n",
        "  m=[]\n",
        "  responseTime = []\n",
        "  if(k==0):\n",
        "    for i in train_data['first_payment_date']:\n",
        "      l.append(int(i.split('/')[0]))\n",
        "    for j in train_data['origination_date']:\n",
        "      m.append(int(j.split('-')[1]))\n",
        "  if(k==1):\n",
        "    for i in train_data['first_payment_date']:\n",
        "      l.append(int(i.split('-')[1]))\n",
        "    for j in train_data['origination_date']:\n",
        "      m.append(int(j.split('/')[0]))\n",
        "  for k in l:\n",
        "    for n in m:\n",
        "      responseTime= k-n\n",
        "  return responseTime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuEpClmvv3th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mdf(train_data):\n",
        "  cols=['val','var0','var1','var2','var3','var4','var5','var6','var7','var8','var9','var10','var11']\n",
        "  mdf=pd.DataFrame(columns=cols)\n",
        "  mdf['val']=df['m1']-df['m12']\n",
        "\n",
        "  for i in range(0,12):\n",
        "    mdf['var0']= df['m1']-df['m2']\n",
        "    mdf['var1']= df['m2']-df['m3']\n",
        "    mdf['var2']= df['m3']-df['m4']\n",
        "    mdf['var3'] = df['m4']-df['m5']\n",
        "    mdf['var4']= df['m5']-df['m6']\n",
        "    mdf['var5']= df['m6']-df['m7']\n",
        "    mdf['var6']= df['m7']-df['m8']\n",
        "    mdf['var7']= df['m8']-df['m9']\n",
        "    mdf['var8'] = df['m9']-df['m10']\n",
        "    mdf['var9']= df['m10']-df['m11']\n",
        "    mdf['var10']= df['m10']-df['m11']\n",
        "    mdf['var11']=df['m11']-df['m12']\n",
        "  mdf.fillna(0)\n",
        "  mdf.replace(' ',0)\n",
        "  return mdf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnPwQwSuMWQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(train_data,k):\n",
        "    train_data['responseTime'] = responseTime(train_data,k)\n",
        "    mdf=mdf(train_data)\n",
        "    train_data.drop(columns = ['origination_date','first_payment_date'],axis =1,inplace = True)\n",
        "    vectorizer = TfidfVectorizer(min_df=10)\n",
        "    fi_tfidf = vectorizer.fit_transform(train_data['financial_institution'])\n",
        "    train_data['source'] = train_data['source'].replace(to_replace=['X','Y','Z'],value=[0,1,2])\n",
        "    print(train_data['source'])\n",
        "    #source=  vectorizer.fit_transform(train_data['source'])\n",
        "    #oan_purposse= vectorizer.fit_transform(train_data['loan_purpose'])\n",
        "\n",
        "    print(\"Shape of matrix after one hot encodig \",fi_tfidf.shape)\n",
        "    #rint(\"Shape of matrix after one hot encodig \",loan_purposse)\n",
        "\n",
        "    dropcolus=['loan_purpose','financial_institution','loan_id','m1','m2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9', 'm10', 'm11', 'm12']\n",
        "\n",
        "    train_data.drop(dropcolus,axis = 1,inplace =True)\n",
        "    print(train_data.columns)\n",
        "    \n",
        "    train_data.fillna(0)\n",
        "    price_scalar = StandardScaler()\n",
        "    price_scalar.fit(train_data.values.reshape(-1,1)) # finding the mean and standard deviation of this data\n",
        "    print(f\"Mean : {price_scalar.mean_[0]}, Standard deviation : {np.sqrt(price_scalar.var_[0])}\")\n",
        "\n",
        "    # Now standardize the data with above maen and variance\n",
        "    if(k==0):\n",
        "        price_standardized = price_scalar.transform(train_data.values.reshape(116058,24))\n",
        "    else:\n",
        "        price_standardized = price_scalar.transform(train_data.values.reshape(35866,24))\n",
        "    X = hstack((fi_tfidf,price_standardized))\n",
        "    X.shape\n",
        "    X=pd.concat([X,mdf],axis=1)\n",
        "    return X\n",
        "# price_standardized = standardScalar.fit(project_data['price'].values)\n",
        "# this will rise the error\n",
        "# ValueError: Expected 2D array, got 1D array instead: array=[725.05 213.03 329.   ... 399.   287.73   5.5 ].\n",
        "# Reshape your data either using array.reshape(-1, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x2U0m8UMWQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = preprocess(train_data,0)\n",
        "X_test = preprocess(test_data,1)\n",
        "\n",
        "# price_standardized = standardScalar.fit(project_data['price'].values)\n",
        "# this will rise the error\n",
        "# ValueError: Expected 2D array, got 1D array instead: array=[725.05 213.03 329.   ... 399.   287.73   5.5 ].\n",
        "# Reshape your data either using array.reshape(-1, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bqA9elIMWQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# with the same hstack function we are concatinating a sparse matrix and a dense matirx :)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrGDseePMWQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# def responseTime(df):\n",
        "#       diff = []\n",
        "#       for i in range(len(df['origination_date'])):\n",
        "#         diff = int(df['first_payment_date'][i].split('/')[0]) - int(df['origination_date'][i].split('-')[1])\n",
        "#         return diff\n",
        "# test_data['responseTime'] = responseTime(test_data)\n",
        "# test_data.drop(columns = ['origination_date','first_payment_date'],axis =1,inplace = True)\n",
        "\n",
        "# # tsne = TSNE(n_components=2, perplexity=30, learning_rate=200)\n",
        "\n",
        "# # X_embedding = tsne.fit_transform(X.toarray())\n",
        "# # # if x is a sparse matrix you need to pass it as X_embedding = tsne.fit_transform(x.toarray()) , .toarray() will convert the sparse matrix into dense matrix\n",
        "\n",
        "# # for_tsne = np.hstack((X_embedding, Labels.reshape(-1,1)))\n",
        "# # for_tsne_df = pd.DataFrame(data=for_tsne, columns=['Dimension_x','Dimension_y','Score'])\n",
        "# # colors = {0:'red', 1:'blue', 2:'green'}\n",
        "# # plt.scatter(for_tsne_df['Dimension_x'], for_tsne_df['Dimension_y'], c=for_tsne_df['Score'].apply(lambda X: colors[x]))\n",
        "# # plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy6M3t_QMWQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state=2)\n",
        "X_train,Labels = sm.fit_sample(X_train,Labels)\n",
        "# from sklearn import svm\n",
        "# wclf = svm.SVC(kernel='linear', class_weight={1:10})\n",
        "# wclf.fit(X, Labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJIEMJg9MWQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn import ensemble\n",
        "# clf1 = ensemble.AdaBoostClassifier(n_estimators=1000)\n",
        "# clf1.fit(train, labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ600U7DMWQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "clf =RandomForestClassifier()\n",
        "params = {'class_weight':[{0:neg_weight, 1:1} for neg_weight in np.arange(1.0, 5.0, 0.5)]} \n",
        "gs = GridSearchCV(estimator=clf, param_grid=params, cv=5)\n",
        "gs.fit(X_train, Labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NT5_VrkDtcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gs.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UonmSYYpMWQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y =gs.predict(X)\n",
        "# sklearn.metrics.f1_score(Labels, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql9f2oRhMWRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# vectorizer = TfidfVectorizer(min_df=10)\n",
        "# fi_tfidf = vectorizer.fit_transform(test_data['financial_institution'])\n",
        "# test_data['source'] = test_data['source'].replace(to_replace=['X','Y','Z'],value=[0,1,2])\n",
        "# print(test_data['source'])\n",
        "# #source=  vectorizer.fit_transform(train_data['source'])\n",
        "# #oan_purposse= vectorizer.fit_transform(train_data['loan_purpose'])\n",
        "\n",
        "# print(\"Shape of matrix after one hot encodig \",fi_tfidf.shape)\n",
        "# #rint(\"Shape of matrix after one hot encodig \",loan_purposse)\n",
        "# from sklearn.decomposition import PCA\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpXTtwwLMWRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dropcolus=['loan_purpose','financial_institution','origination_date','first_payment_date','loan_id']\n",
        "# z= test_data.drop(dropcolus,axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON44JGzKMWRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # price_standardized = standardScalar.fit(project_data['price'].values)\n",
        "# # this will rise the error\n",
        "# # ValueError: Expected 2D array, got 1D array instead: array=[725.05 213.03 329.   ... 399.   287.73   5.5 ].\n",
        "# # Reshape your data either using array.reshape(-1, 1)\n",
        "\n",
        "# price_scalar = StandardScaler()\n",
        "# price_scalar.fit(z.values.reshape(-1,1)) # finding the mean and standard deviation of this data\n",
        "# print(f\"Mean : {price_scalar.mean_[0]}, Standard deviation : {np.sqrt(price_scalar.var_[0])}\")\n",
        "\n",
        "# # Now standardize the data with above maen and variance.\n",
        "\n",
        "# price_standardize = price_scalar.transform(z.values.reshape(35866,23 ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKP126TCMWRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# # with the same hstack function we are concatinating a sparse matrix and a dense matirx :)\n",
        "# Z = hstack((fi_tfidf,price_standardize))\n",
        "# Z.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odh0LH-MMWRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pred =gs.predict(Z)\n",
        "# predictions = clf1.predict_proba(Z)[:,1]\n",
        "# # for i in pred:\n",
        "# #     if(i==1):\n",
        "# #         print(\"Hurray\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCQjiarHMWRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adaboost(X_train, X_test, y_train):\n",
        "    model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train,y_train)\n",
        "    y_pred = model.predict(X_test) \n",
        "    return y_pred\n",
        "# AdaBoost\n",
        "y_baseline = adaboost(X_train, X_test, Labels)\n",
        "# SMOTE\n",
        "# sm = SMOTE(random_state=42)\n",
        "# X_train_sm, Labels = sm.fit_sample(X_train, Labels)\n",
        "# y_smote = adaboost(X_train_sm, X_test, Labels)\n",
        "# # RUS\n",
        "# X_full = X_train.copy()\n",
        "# X_full['target'] = Labels[1]\n",
        "# X_maj = X_full[X_full.target==0]\n",
        "# X_min = X_full[X_full.target==1]\n",
        "# X_maj_rus = resample(X_maj,replace=False,n_samples=len(X_min),random_state=44)\n",
        "# X_rus = pd.concat([X_maj_rus, X_min])\n",
        "# X_train_rus = X_rus.drop(['target'], axis=1)\n",
        "# y_train_rus = X_rus.target\n",
        "# y_rus = adaboost(X_train_rus, X_test, y_train_rus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMIJq_GSMWRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sklearn.metrics.f1_score(Labels, X_test)\n",
        "test_data1 = pd.read_csv(\"test.csv\")\n",
        "cols=['loan_id','m13']\n",
        "output=pd.DataFrame(columns=cols)\n",
        "print(output.columns)\n",
        "output['loan_id']=test_data1['loan_id']\n",
        "output['m13']=y_baseline\n",
        "output.to_csv(\"pred1.csv\", index=False, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}